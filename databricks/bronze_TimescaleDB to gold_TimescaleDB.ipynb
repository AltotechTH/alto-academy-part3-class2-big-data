{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f67fe5e-5529-4dfb-aa32-722dbc804de3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Extract data from TimescaleDB, aggregate it and load the aggregated data back to TimescaleDB. \n",
    "\n",
    "This notebook shows you how to import and aggregate data from JDBC TimescaleDB database back into a TimescaleDB database using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68188358-233e-4afe-a93f-382ac29ce71e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 0: Set Timezone & Get the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09792bd4-e113-4e96-8f1d-c9c038064da1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3736157526499560>, line 6\u001B[0m\n",
       "\u001B[1;32m      3\u001B[0m spark\u001B[38;5;241m.\u001B[39mconf\u001B[38;5;241m.\u001B[39mset(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspark.sql.session.timeZone\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsia/Bangkok\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# the resample period has to be in minute\u001B[39;00m\n",
       "\u001B[0;32m----> 6\u001B[0m resample_period \u001B[38;5;241m=\u001B[39m dbutils\u001B[38;5;241m.\u001B[39mwidgets\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresample_period\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resample_period, \u001B[38;5;28mint\u001B[39m):\n",
       "\u001B[1;32m      8\u001B[0m     resample_period \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(resample_period)\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/WidgetHandlerImpl.py:42\u001B[0m, in \u001B[0;36mWidgetsHandlerImpl.get\u001B[0;34m(self, name)\u001B[0m\n",
       "\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, name):\n",
       "\u001B[1;32m     37\u001B[0m     \u001B[38;5;124;03m\"\"\" Returns the current value of a widget with give name.\u001B[39;00m\n",
       "\u001B[1;32m     38\u001B[0m \n",
       "\u001B[1;32m     39\u001B[0m \u001B[38;5;124;03m    :param name: Name of the argument to be accessed\u001B[39;00m\n",
       "\u001B[1;32m     40\u001B[0m \u001B[38;5;124;03m    :return: Current value of the widget or default value\u001B[39;00m\n",
       "\u001B[1;32m     41\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m---> 42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_notebookArguments\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetArgument\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_entry_point\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetCurrentBindings\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:188\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdeco\u001B[39m(\u001B[38;5;241m*\u001B[39ma: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n",
       "\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 188\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    189\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    190\u001B[0m         converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n",
       "\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n",
       "\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n",
       "\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n",
       "\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n",
       "\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n",
       "\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
       "\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o362.getArgument.\n",
       ": com.databricks.dbutils_v1.InputWidgetNotDefined: No input widget named resample_period is defined\n",
       "\tat com.databricks.backend.daemon.driver.NotebookArguments.checkExists(NotebookArguments.scala:74)\n",
       "\tat com.databricks.backend.daemon.driver.NotebookArguments.getArgument(NotebookArguments.scala:266)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\nFile \u001B[0;32m<command-3736157526499560>, line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m spark\u001B[38;5;241m.\u001B[39mconf\u001B[38;5;241m.\u001B[39mset(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspark.sql.session.timeZone\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsia/Bangkok\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# the resample period has to be in minute\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m resample_period \u001B[38;5;241m=\u001B[39m dbutils\u001B[38;5;241m.\u001B[39mwidgets\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresample_period\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resample_period, \u001B[38;5;28mint\u001B[39m):\n\u001B[1;32m      8\u001B[0m     resample_period \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(resample_period)\n\nFile \u001B[0;32m/databricks/python_shell/dbruntime/WidgetHandlerImpl.py:42\u001B[0m, in \u001B[0;36mWidgetsHandlerImpl.get\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, name):\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;124;03m\"\"\" Returns the current value of a widget with give name.\u001B[39;00m\n\u001B[1;32m     38\u001B[0m \n\u001B[1;32m     39\u001B[0m \u001B[38;5;124;03m    :param name: Name of the argument to be accessed\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;124;03m    :return: Current value of the widget or default value\u001B[39;00m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_notebookArguments\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetArgument\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_entry_point\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetCurrentBindings\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:188\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdeco\u001B[39m(\u001B[38;5;241m*\u001B[39ma: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 188\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    190\u001B[0m         converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o362.getArgument.\n: com.databricks.dbutils_v1.InputWidgetNotDefined: No input widget named resample_period is defined\n\tat com.databricks.backend.daemon.driver.NotebookArguments.checkExists(NotebookArguments.scala:74)\n\tat com.databricks.backend.daemon.driver.NotebookArguments.getArgument(NotebookArguments.scala:266)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n\tat java.lang.Thread.run(Thread.java:750)\n",
       "errorSummary": "com.databricks.dbutils_v1.InputWidgetNotDefined: No input widget named resample_period is defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set the timezone of the spark session\n",
    "# otherwise the timezone information of data from TimescaleDB disapper\n",
    "spark.conf.set(\"spark.sql.session.timeZone\", \"Asia/Bangkok\")\n",
    "\n",
    "# the resample period has to be in minute\n",
    "resample_period = dbutils.widgets.get(\"resample_period\")\n",
    "if not isinstance(resample_period, int):\n",
    "    resample_period = int(resample_period)\n",
    "\n",
    "table_name = dbutils.widgets.get(\"table_name\")\n",
    "destination_table_name = dbutils.widgets.get(\"destination_table_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "064e6786-c940-4ee4-a4e9-ae038155a1da",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Step 1: Connection information\n",
    "\n",
    "First define some variables to programmatically create these connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c86509b5-3bd9-412e-ab8f-b109dd1154d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jdbc:postgresql://alto-workshop-timescaledb.postgres.database.azure.com:5432/postgres\n"
     ]
    }
   ],
   "source": [
    "driver = \"org.postgresql.Driver\"\n",
    "\n",
    "database_host = \"alto-workshop-timescaledb.postgres.database.azure.com\"\n",
    "database_port = \"5432\" # update if you use a non-default port\n",
    "database_name = \"postgres\" # eg. postgres\n",
    "user = \"solemnLizard\"\n",
    "password = \"af6f4b55-48e0-4fe1-a2b6-67869a28776e\"\n",
    "\n",
    "url = f\"jdbc:postgresql://{database_host}:{database_port}/{database_name}\"\n",
    "\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88cb943a-71ea-47e4-919c-e2efd039cbd3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 2: Constructing the filter\n",
    "\n",
    "We will filter out the data between certain time periods.\n",
    "\n",
    "For now, we will get the current timestamp with ```pendulum``` library. In this case, we can't really do retry or backfilling. We may need to improve this somehow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dffc6f6c-3cda-46d7-96f4-0f95cdd0bda1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3736157526499557>, line 5\u001B[0m\n",
       "\u001B[1;32m      3\u001B[0m end \u001B[38;5;241m=\u001B[39m pendulum\u001B[38;5;241m.\u001B[39mnow(tz\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAsia/Bangkok\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# check if the end is every resample_period minutes\u001B[39;00m\n",
       "\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m end\u001B[38;5;241m.\u001B[39mminute \u001B[38;5;241m%\u001B[39m resample_period \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\u001B[1;32m      6\u001B[0m     \u001B[38;5;66;03m# change the seconds and micro seconds to 0\u001B[39;00m\n",
       "\u001B[1;32m      7\u001B[0m     end \u001B[38;5;241m=\u001B[39m end\u001B[38;5;241m.\u001B[39mset(second\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, microsecond\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m      9\u001B[0m     \u001B[38;5;66;03m# if not, round it down to the nearest resample_period minutes\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: unsupported operand type(s) for %: 'int' and 'str'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-3736157526499557>, line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m end \u001B[38;5;241m=\u001B[39m pendulum\u001B[38;5;241m.\u001B[39mnow(tz\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAsia/Bangkok\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# check if the end is every resample_period minutes\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m end\u001B[38;5;241m.\u001B[39mminute \u001B[38;5;241m%\u001B[39m resample_period \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;66;03m# change the seconds and micro seconds to 0\u001B[39;00m\n\u001B[1;32m      7\u001B[0m     end \u001B[38;5;241m=\u001B[39m end\u001B[38;5;241m.\u001B[39mset(second\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, microsecond\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;66;03m# if not, round it down to the nearest resample_period minutes\u001B[39;00m\n\n\u001B[0;31mTypeError\u001B[0m: unsupported operand type(s) for %: 'int' and 'str'",
       "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: unsupported operand type(s) for %: 'int' and 'str'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pendulum\n",
    "\n",
    "end = pendulum.now(tz='Asia/Bangkok')\n",
    "# check if the end is every resample_period minutes\n",
    "if end.minute % resample_period == 0:\n",
    "    # change the seconds and micro seconds to 0\n",
    "    end = end.set(second=0, microsecond=0)\n",
    "else:\n",
    "    # if not, round it down to the nearest resample_period minutes\n",
    "    end = end.subtract(minutes=end.minute % resample_period)\n",
    "    # change the seconds and micro seconds to 0\n",
    "    end = end.set(second=0, microsecond=0)\n",
    "\n",
    "# start is resample_period minutes before end\n",
    "start = end.subtract(minutes=resample_period)\n",
    "\n",
    "extract_query = f\"\"\"(SELECT * FROM {table_name} WHERE timestamp >= '{start}' AND timestamp < '{end}') as filtered_data\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "165cb68e-c818-4c26-8157-2a47b553bb84",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Step 2: Reading the data\n",
    "\n",
    "We will extract the data from **TimescaleDB** with the above filter applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9b34fa8-1e55-41aa-926f-60e17096434c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_table = (spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"driver\", driver)\n",
    "    .option(\"url\", url)\n",
    "    .option(\"dbtable\", extract_query)\n",
    "    .option(\"user\", user)\n",
    "    .option(\"password\", password)\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a2ef8b6-1e42-4ac1-9130-83270cf66906",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>timestamp</th><th>device_id</th><th>aggregation_type</th><th>datapoint</th><th>value</th></tr></thead><tbody><tr><td>2023-09-28T13:59:00.000+0700</td><td>eb27641363d2b2a091jdar</td><td>mode_1min</td><td>online_status</td><td>\"online\"</td></tr><tr><td>2023-09-28T13:59:00.000+0700</td><td>eb27641363d2b2a091jdar</td><td>mode_1min</td><td>presence_state</td><td>\"unoccupied\"</td></tr><tr><td>2023-09-28T13:59:00.000+0700</td><td>eb27641363d2b2a091jdar</td><td>mean_1min</td><td>sensitivity</td><td>100.0</td></tr><tr><td>2023-09-28T13:59:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_1min</td><td>noise</td><td>72.0</td></tr><tr><td>2023-09-28T13:59:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_1min</td><td>temperature</td><td>27.0</td></tr><tr><td>2023-09-28T13:59:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_1min</td><td>co2</td><td>421.0</td></tr><tr><td>2023-09-28T13:59:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_1min</td><td>pm25</td><td>2.0</td></tr><tr><td>2023-09-28T13:59:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_1min</td><td>illuminance</td><td>40.0</td></tr><tr><td>2023-09-28T13:59:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_1min</td><td>humidity</td><td>75.0</td></tr><tr><td>2023-09-28T13:58:00.000+0700</td><td>eb27641363d2b2a091jdar</td><td>mode_1min</td><td>online_status</td><td>\"online\"</td></tr><tr><td>2023-09-28T13:58:00.000+0700</td><td>eb27641363d2b2a091jdar</td><td>mode_1min</td><td>presence_state</td><td>\"unoccupied\"</td></tr><tr><td>2023-09-28T13:58:00.000+0700</td><td>eb27641363d2b2a091jdar</td><td>mean_1min</td><td>sensitivity</td><td>100.0</td></tr><tr><td>2023-09-28T13:58:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_1min</td><td>noise</td><td>72.0</td></tr><tr><td>2023-09-28T13:58:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_1min</td><td>temperature</td><td>27.0</td></tr><tr><td>2023-09-28T13:58:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_1min</td><td>co2</td><td>424.0</td></tr><tr><td>2023-09-28T13:58:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_1min</td><td>illuminance</td><td>41.0</td></tr><tr><td>2023-09-28T13:58:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_1min</td><td>pm25</td><td>2.0</td></tr><tr><td>2023-09-28T13:58:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_1min</td><td>humidity</td><td>75.0</td></tr><tr><td>2023-09-28T13:55:00.000+0700</td><td>eb27641363d2b2a091jdar</td><td>mode_1min</td><td>online_status</td><td>\"online\"</td></tr><tr><td>2023-09-28T13:55:00.000+0700</td><td>eb27641363d2b2a091jdar</td><td>mode_1min</td><td>presence_state</td><td>\"unoccupied\"</td></tr><tr><td>2023-09-28T13:55:00.000+0700</td><td>eb27641363d2b2a091jdar</td><td>mean_1min</td><td>sensitivity</td><td>100.0</td></tr><tr><td>2023-09-28T13:55:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_1min</td><td>noise</td><td>71.0</td></tr><tr><td>2023-09-28T13:55:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_1min</td><td>temperature</td><td>27.0</td></tr><tr><td>2023-09-28T13:55:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_1min</td><td>co2</td><td>421.0</td></tr><tr><td>2023-09-28T13:55:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_1min</td><td>illuminance</td><td>41.0</td></tr><tr><td>2023-09-28T13:55:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_1min</td><td>pm25</td><td>2.0</td></tr><tr><td>2023-09-28T13:55:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_1min</td><td>humidity</td><td>75.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2023-09-28T13:59:00.000+0700",
         "eb27641363d2b2a091jdar",
         "mode_1min",
         "online_status",
         "\"online\""
        ],
        [
         "2023-09-28T13:59:00.000+0700",
         "eb27641363d2b2a091jdar",
         "mode_1min",
         "presence_state",
         "\"unoccupied\""
        ],
        [
         "2023-09-28T13:59:00.000+0700",
         "eb27641363d2b2a091jdar",
         "mean_1min",
         "sensitivity",
         "100.0"
        ],
        [
         "2023-09-28T13:59:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_1min",
         "noise",
         "72.0"
        ],
        [
         "2023-09-28T13:59:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_1min",
         "temperature",
         "27.0"
        ],
        [
         "2023-09-28T13:59:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_1min",
         "co2",
         "421.0"
        ],
        [
         "2023-09-28T13:59:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_1min",
         "pm25",
         "2.0"
        ],
        [
         "2023-09-28T13:59:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_1min",
         "illuminance",
         "40.0"
        ],
        [
         "2023-09-28T13:59:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_1min",
         "humidity",
         "75.0"
        ],
        [
         "2023-09-28T13:58:00.000+0700",
         "eb27641363d2b2a091jdar",
         "mode_1min",
         "online_status",
         "\"online\""
        ],
        [
         "2023-09-28T13:58:00.000+0700",
         "eb27641363d2b2a091jdar",
         "mode_1min",
         "presence_state",
         "\"unoccupied\""
        ],
        [
         "2023-09-28T13:58:00.000+0700",
         "eb27641363d2b2a091jdar",
         "mean_1min",
         "sensitivity",
         "100.0"
        ],
        [
         "2023-09-28T13:58:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_1min",
         "noise",
         "72.0"
        ],
        [
         "2023-09-28T13:58:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_1min",
         "temperature",
         "27.0"
        ],
        [
         "2023-09-28T13:58:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_1min",
         "co2",
         "424.0"
        ],
        [
         "2023-09-28T13:58:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_1min",
         "illuminance",
         "41.0"
        ],
        [
         "2023-09-28T13:58:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_1min",
         "pm25",
         "2.0"
        ],
        [
         "2023-09-28T13:58:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_1min",
         "humidity",
         "75.0"
        ],
        [
         "2023-09-28T13:55:00.000+0700",
         "eb27641363d2b2a091jdar",
         "mode_1min",
         "online_status",
         "\"online\""
        ],
        [
         "2023-09-28T13:55:00.000+0700",
         "eb27641363d2b2a091jdar",
         "mode_1min",
         "presence_state",
         "\"unoccupied\""
        ],
        [
         "2023-09-28T13:55:00.000+0700",
         "eb27641363d2b2a091jdar",
         "mean_1min",
         "sensitivity",
         "100.0"
        ],
        [
         "2023-09-28T13:55:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_1min",
         "noise",
         "71.0"
        ],
        [
         "2023-09-28T13:55:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_1min",
         "temperature",
         "27.0"
        ],
        [
         "2023-09-28T13:55:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_1min",
         "co2",
         "421.0"
        ],
        [
         "2023-09-28T13:55:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_1min",
         "illuminance",
         "41.0"
        ],
        [
         "2023-09-28T13:55:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_1min",
         "pm25",
         "2.0"
        ],
        [
         "2023-09-28T13:55:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_1min",
         "humidity",
         "75.0"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"scale\":6}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(128)\",\"scale\":0}",
         "name": "device_id",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(32)\",\"scale\":0}",
         "name": "aggregation_type",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(64)\",\"scale\":0}",
         "name": "datapoint",
         "type": "\"string\""
        },
        {
         "metadata": "{\"scale\":0}",
         "name": "value",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view the dataframe\n",
    "if not source_table.isEmpty():\n",
    "  display(source_table)\n",
    "else:\n",
    "  print(f\"There is no data between {start} and {end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b0135c7-328a-4de3-8f04-ab9d1e6c77de",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 3: Aggregate the data\n",
    "\n",
    "We will aggregate the data based on resample_period.\n",
    "\n",
    "Currently we only support the ```mean``` function for \"numeric\" values and ```mode``` for \"string\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a8b85e3-fda7-4f62-a896-dcc09a446ef9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if source_table.isEmpty():\n",
    "  print(f\"There is no data between {start} and {end}\")\n",
    "else:\n",
    "  from pyspark.sql import functions as F\n",
    "\n",
    "  # convert to value that can be used in spark window function\n",
    "  resample_period = '{} minutes'.format(resample_period)\n",
    "\n",
    "  # separate the df based on the datatype of the \"value\" column\n",
    "  numeric_df = source_table.filter(source_table[\"value\"].cast(\"double\").isNotNull())\n",
    "  string_df  = source_table.filter(source_table[\"value\"].cast(\"double\").isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a2818b1-ae98-45a4-9ad4-a5afefa31468",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean, avg, floor, window, min, mode, lit\n",
    "\n",
    "if source_table.isEmpty():\n",
    "  print(f\"There is no data between {start} and {end}\")\n",
    "else:\n",
    "  if numeric_df.isEmpty():\n",
    "    pass\n",
    "  else:\n",
    "    window_spec = window(\"timestamp\", f\"{resample_period}\")\n",
    "    numeric_df = numeric_df.groupBy(\"device_id\", \"datapoint\", window_spec).agg(\n",
    "      mean(\"value\").alias(\"value\"),\n",
    "      min(\"timestamp\").alias(\"timestamp\")\n",
    "    )\n",
    "    numeric_df = numeric_df.withColumn(\"aggregation_type\", lit(f\"mean_{resample_period}\"))\n",
    "\n",
    "  if string_df.isEmpty():\n",
    "    pass\n",
    "  else:\n",
    "    window_spec = window(\"timestamp\", f\"{resample_period}\")\n",
    "    string_df = string_df.groupBy(\"device_id\", \"datapoint\", window_spec).agg(\n",
    "      mode(\"value\").alias(\"value\"),\n",
    "      min(\"timestamp\").alias(\"timestamp\")\n",
    "    )\n",
    "    string_df = string_df.withColumn(\"aggregation_type\", lit(f\"mode_{resample_period}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "782ea698-a127-4e8c-a9be-a0c6f004c022",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>timestamp</th><th>device_id</th><th>aggregation_type</th><th>datapoint</th><th>value</th></tr></thead><tbody><tr><td>2023-09-28T13:55:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_5 minutes</td><td>illuminance</td><td>40.666666666666664</td></tr><tr><td>2023-09-28T13:55:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_5 minutes</td><td>temperature</td><td>27.0</td></tr><tr><td>2023-09-28T13:55:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_5 minutes</td><td>co2</td><td>422.0</td></tr><tr><td>2023-09-28T13:55:00.000+0700</td><td>eb27641363d2b2a091jdar</td><td>mean_5 minutes</td><td>sensitivity</td><td>100.0</td></tr><tr><td>2023-09-28T13:55:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_5 minutes</td><td>noise</td><td>71.66666666666667</td></tr><tr><td>2023-09-28T13:55:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_5 minutes</td><td>humidity</td><td>75.0</td></tr><tr><td>2023-09-28T13:55:00.000+0700</td><td>eba63b92a045a9e8dbibaj</td><td>mean_5 minutes</td><td>pm25</td><td>2.0</td></tr><tr><td>2023-09-28T13:55:00.000+0700</td><td>eb27641363d2b2a091jdar</td><td>mode_5 minutes</td><td>online_status</td><td>\"online\"</td></tr><tr><td>2023-09-28T13:55:00.000+0700</td><td>eb27641363d2b2a091jdar</td><td>mode_5 minutes</td><td>presence_state</td><td>\"unoccupied\"</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2023-09-28T13:55:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_5 minutes",
         "illuminance",
         "40.666666666666664"
        ],
        [
         "2023-09-28T13:55:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_5 minutes",
         "temperature",
         "27.0"
        ],
        [
         "2023-09-28T13:55:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_5 minutes",
         "co2",
         "422.0"
        ],
        [
         "2023-09-28T13:55:00.000+0700",
         "eb27641363d2b2a091jdar",
         "mean_5 minutes",
         "sensitivity",
         "100.0"
        ],
        [
         "2023-09-28T13:55:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_5 minutes",
         "noise",
         "71.66666666666667"
        ],
        [
         "2023-09-28T13:55:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_5 minutes",
         "humidity",
         "75.0"
        ],
        [
         "2023-09-28T13:55:00.000+0700",
         "eba63b92a045a9e8dbibaj",
         "mean_5 minutes",
         "pm25",
         "2.0"
        ],
        [
         "2023-09-28T13:55:00.000+0700",
         "eb27641363d2b2a091jdar",
         "mode_5 minutes",
         "online_status",
         "\"online\""
        ],
        [
         "2023-09-28T13:55:00.000+0700",
         "eb27641363d2b2a091jdar",
         "mode_5 minutes",
         "presence_state",
         "\"unoccupied\""
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(128)\",\"scale\":0}",
         "name": "device_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "aggregation_type",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(64)\",\"scale\":0}",
         "name": "datapoint",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "value",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if source_table.isEmpty():\n",
    "  print(f\"There is no data between {start} and {end}\")\n",
    "else:\n",
    "  if numeric_df.isEmpty() and string_df.isEmpty():\n",
    "    df_to_export = None\n",
    "  elif not numeric_df.isEmpty() and string_df.isEmpty():\n",
    "    df_to_export = numeric_df\n",
    "  elif numeric_df.isEmpty() and not string_df.isEmpty():\n",
    "    df_to_export = string_df\n",
    "  elif not numeric_df.isEmpty() and not string_df.isEmpty():\n",
    "    # concat the two dataframes\n",
    "    df_to_export = numeric_df.union(string_df)\n",
    "  if df_to_export is None:\n",
    "    pass\n",
    "  else:\n",
    "    df_to_export = df_to_export.select(\"timestamp\",\"device_id\", \"aggregation_type\", \"datapoint\", \"value\")\n",
    "    display(df_to_export)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71da4b47-b5f2-46a5-8025-83d9c8714303",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 4: Write data to TimescaleDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c00014c-63e3-4f87-9f3d-86cf75af379f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if source_table.isEmpty():\n",
    "  print(f\"There is no data between {start} and {end}\")\n",
    "else:\n",
    "  if df_to_export is None:\n",
    "    pass\n",
    "  else:\n",
    "    if not df_to_export.isEmpty():\n",
    "      df_to_export.write.jdbc(\n",
    "        url=url,\n",
    "        table=destination_table_name,\n",
    "        mode='overwrite',\n",
    "        properties= {\n",
    "          'user': user,\n",
    "          'password': password\n",
    "        }\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32ed539c-58c5-4ff4-8ccb-3e49be7869c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3736157526499546,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "bronze_TimescaleDB to gold_TimescaleDB",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
